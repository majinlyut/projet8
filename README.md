# Ticket Stream Processor

Un producteur-consommateur Redpanda en Python pour simuler un syst√®me de tickets clients en temps r√©el.

## üöÄ Fonctionnalit√©s

- Production de messages Kafka simulant des tickets clients
- Traitement en temps r√©el avec PySpark
- Architecture conteneuris√©e avec Docker Compose
- Monitoring possible via Redpanda Console 

## üõ†Ô∏è Stack technique

- Python 3.10+
- Kafka / Redpanda
- PySpark
- Docker & Docker Compose

## üìÅ Structure du projet

```
.
‚îú‚îÄ‚îÄ producer/                 # Producteur Kafka (Python)
‚îÇ   ‚îî‚îÄ‚îÄ producer_ticket.py
‚îú‚îÄ‚îÄ consumer/                 # Consommateur PySpark
‚îÇ   ‚îî‚îÄ‚îÄ consumer_ticket.py
‚îú‚îÄ‚îÄ docker-compose.yml
‚îî‚îÄ‚îÄ README.md
```
## üìä Diagramme du pipeline

```mermaid
flowchart LR
    A[Producer Python] -->|envoie messages JSON| B[Redpanda Broker]
    B -->|consomm√© via Spark Streaming| C[Consumer PySpark]
    C -->|traitement + agr√©gation| D[R√©sultats en m√©moire/logs]
    B -->|monitoring| E[Redpanda Console]
```

## üß™ Lancer le projet en local

1. Cloner le d√©p√¥t  
   ```bash
   git clone https://https://github.com/majinlyut/projet8.git
   cd ticket-stream-processor
   ```

2. Lancer les services avec Docker Compose  
   ```bash
   docker-compose up --build
   ```

3. Acc√©der √† la Redpanda Console 
   [http://localhost:8080](http://localhost:8080)

4. Consulter les tickets cr√©es
   ```bash
   docker-compose logs -f consumer
   ```
   
5. Consulter les tickets trait√©s par Spark
   ```bash
   docker-compose logs -f producer
   ```

## üé• D√©mo en vid√©o

[![Watch the video](https://img.youtube.com/vi/pB50tTuo0IM/maxresdefault.jpg)](https://www.youtube.com/watch?v=pB50tTuo0IM)



